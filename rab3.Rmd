---
title: "Упражнение 3"
author: ""
date: '25 февраля 2017 г '
output: html_document
---

Цель: исследовать набор данных `Auto.1` с помощью линейной регрессионной модели. Задействовав все возможные регрессоры, сделать вывод о пригодности модели для прогноза. Сравнить с методом k ближайших соседей по MSE на тестовой выборке.    

```{r Данные и пакеты, include = F}
library('GGally')
library('lmtest')
library('FNN')
library('ISLR')
data(Auto)

pairs(Auto)

# константы
my.seed <- 12345
train.percent <- 0.85


Auto.1 <- data.frame(mpg = Auto$mpg, 
                     weight = Auto$weight, 
                     acceleration = Auto$acceleration,
                     year = Auto$year, 
                     cylinders = Auto$cylinders) 

Auto.1$cylinders <- as.factor(Auto.1$cylinders)

# обучающая выборка
set.seed(my.seed)
inTrain <- sample(seq_along(Auto.1$mpg), 
                  nrow(Auto.1) * train.percent)
df.train <- Auto.1[inTrain, c(colnames(Auto.1)[-1], colnames(Auto.1)[1])]
df.test <- Auto.1[-inTrain, -1]

```

## Описание переменных  

Набор данных `Auto.1` содержит информацию по автомобилям. Переменные:  

- `mpg` – миль на галлон;  
- `weight` – вес автомобиля (фунты);
- `acceleration` – время разгона (от 0 до 60 миль / ч (сек.));  
- `year` - модельный год (по модулю 100);
- `cylinders` – количество цилиндров (от 4 до 8).

Размерность обучающей выборки: $n = `r dim(df.train)[1]`$ строк, $p = `r dim(df.train)[2] - 1`$ объясняющих переменных. Зависимая переменная -- `mpg`.  

```{r Описание данных, message = F, warning = F}
# описательные статистики по переменным
summary(df.train)

# совместный график разброса переменных
ggpairs(df.train)

# цвета по фактору 
ggpairs(df.train[, c('weight', 'cylinders', 'acceleration', 'year')], 
        mapping = ggplot2::aes(color = cylinders))

```

## Модели  

```{r warning = F, error = F}

model.1 <- lm(mpg ~ . + cylinders:weight + cylinders:acceleration + cylinders:year,
              data = df.train)
summary(model.1)

```

Совместное влияние `weight:cylinders ` исключаем, т.к. параметры незначимы.

```{r warning = F, error = F}

model.2 <- lm(mpg ~ . + cylinders:acceleration + cylinders:year,
              data = df.train)
summary(model.2)

```

Взаимодействие `acceleration:cylinders` также исключаем в связи с незначимостью параметров.


```{r warning = F, error = F}

model.3 <- lm(mpg ~ . + cylinders:year,
              data = df.train)
summary(model.3)

```

Коэффициент при `cylinders4` наименее значимый.

```{r warning = F, error = F}

model.4 <- lm(mpg ~ weight + acceleration + year,
              data = df.train)
summary(model.4)

```

Коэффициент при `acceleration` не значим. Перестраиваем модель.

```{r warning = F, error = F}

model.5 <- lm(mpg ~ weight + year,
              data = df.train)
summary(model.5)

```

Остановимся на последней построенной модели, поскольку все её параметры значимы и она обладает достаточно высокими характеристиками качества.

# Проверка остатков  

```{r warning = F, error = F}
# тест Бройша-Пагана
bptest(model.5)

# статистика Дарбина-Уотсона
dwtest(model.5)

# графики остатков
par(mar = c(4.5, 4.5, 2, 1))
par(mfrow = c(1, 3))
plot(model.5, 1)
plot(model.5, 4)
plot(model.5, 5)
par(mfrow = c(1, 1))

```

Тест Бройша-Пагана: p-значение = 0.002155 < 0.05; нулевая гипотеза о гомоскедастичности отвергается. Проявилась гетероскедастичность. Статистика Дарбина-Уотсона: p-значение = 0.9597 > 0.05; нет смысла отвергать нулевую гипотезу об отсутствии автокорреляции.

# Сравнение с kNN

```{r }
# фактические значения y на тестовой выборке
y.fact <- Auto.1[-inTrain, 1]
y.model.lm <- predict(model.5, df.test)
MSE.lm <- sum((y.model.lm - y.fact)^2) / length(y.model.lm)

# kNN требует на вход только числовые переменные
df.train.num <- as.data.frame(apply(df.train, 2, as.numeric))
df.test.num <- as.data.frame(apply(df.test, 2, as.numeric))

for (i in 2:50){
    model.knn <- knn.reg(train = df.train.num[, !(colnames(df.train.num) %in% 'mpg')], 
                     y = df.train.num[, 'mpg'], 
                     test = df.test.num, k = i)
    y.model.knn <- model.knn$pred
    if (i == 2){
        MSE.knn <- sum((y.model.knn - y.fact)^2) / length(y.model.knn)
    } else {
        MSE.knn <- c(MSE.knn, 
                     sum((y.model.knn - y.fact)^2) / length(y.model.knn))
    }
}

# график
par(mar = c(4.5, 4.5, 1, 1))
plot(2:50, MSE.knn, type = 'b', col = 'darkgreen',
     xlab = 'значение k', ylab = 'MSE на тестовой выборке')
lines(2:50, rep(MSE.lm, 49), lwd = 2, col = grey(0.2), lty = 2)
legend('bottomright', lty = c(1, 2), pch = c(1, NA), 
       col = c('darkgreen', grey(0.2)), 
       legend = c('k ближайших соседа', 'регрессия (все факторы)'), 
       lwd = rep(2, 2))
```

# Пригодна ли построенная модель регрессии для прогнозирования?

Построенная модель обладает достаточно высокими характеристиками качества. Результат теста Бройша-Пагана удовлетворителен. Значение статистики Дарбина-Уотсона также удовлетворительно. Построенная модель регрессии вполне пригодна для прогнозирования.
